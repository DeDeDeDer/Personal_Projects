# Personal_Projects
This GitHub holds all my personal project's that I have worked on as a past time. 
Project's are mainly focus on Data Science, Insurance Pricing & Reserving fields.
<br>A mapping of these are laid out below.
![ScreenShot](/Pictures/MapBackground_4.png)
<br>
<br>


<br>

# **What is Predictive Modelling?**

<br>
It is simply the framework to integrate past data & statistics to predict 
future outcomes or project liabilities. There are 4 main techniques;
Bayesian, Decision Trees, Support Vector Machines & Neural Networks.
My project's utilizes mainly Bayesian & Decision Tree techniques.
Hence, focused primarily on linear regression models.
<br>


.
<br>
## [At Its Simplest, Predictive Modelling](https://medium.com/@DRicky.Ch29/at-its-simplest-predictive-modelling-b3c0c0b0716d)
<br>

![ScreenShot](/Pictures/IntroModel_1.png)

An article publication aimed at explaining concepts to:
<br>1. Generalised structure to Predictive Modelling
<br>2. Alternative interpretations to various statistical model metrics
<br>
<br>The article follows the generalized framework of:
<br>
<ol><ins>Data preparation</ins></ol>
<ol>- Preliminary data analysis, executing 4-Tier's of data cleaning.</ol>

<ol><ins>Exploratory Data Analysis</ins></ol>
<ol>- Uni- Bi- & Multi- Analysis</ol>

<ol><ins>Model Preparation</ins></ol>
<ol>- Data stratified Train/Test splits, Hyper parameter tuning, parameter evaluation metrics.</ol>
<ol>- Feature Engineering (Quantity & Quality), Feature evaluation metrics</ol>

<ol><ins>Predictive Modelling (Classification Problem)</ins></ol>
<ol>- Ensembles (Hard & Soft Voting)</ol>

<br>
<a href="https://medium.com/@DRicky.Ch29/at-its-simplest-predictive-modelling-b3c0c0b0716d"><strong>Click To View</strong></a>
<br>



<br>

# **What is Web Scraping?**

<br>
In short, it is simply the automated process of extracting data from the web. 
Subsequently, cleaning any irregularities & conducting Exploratory Data Analysis
to spot Trends & Patterns.
<br>

.
<br>
## [Python Web Scraping PDF & Data Cleaning (Part 1)](https://medium.com/@DRicky.Ch29/web-scraping-pdf-tables-data-cleaning-part-1-cb6d8d47a6de)
<br>

![ScreenShot](/Pictures/WebScrapPart1.png)

A Python Kernel written to automate repetitive clicking of 1,228c URLs &
converting 1,000c PDF Tables into CSV to compile data.

<br>Contents:
<ol>1. Collate online source code URLs & sub-page URLs</ol>
<ol>2. Download online data via URLs</ol>
<ol>3. Convert & Neaten PDF Table into CSV</ol>
<ol>4. Compile all CSV Tables</ol>

<br>
<a href="https://medium.com/@DRicky.Ch29/web-scraping-pdf-tables-data-cleaning-part-1-cb6d8d47a6de"><strong>Click To View</strong></a>
<br>



.
<br>
## [Python Web Scraping Data Analysis Motor Insurance (Part 2)](https://medium.com/@DRicky.Ch29/python-web-scraping-data-analysis-motor-insurance-part-2-4cd7162ba644)
<br>

![ScreenShot](/Pictures/WebScrapPart2.png)

After extracting Annual Insurance Data Returns in the Part 1 series, we proceed to
analyze the data.

<br>Contents:
<ol><ins>Patterns</ins></ol>
<ol>1. Benchmark Range of ROC on Expense & Loss Ratios</ol>

<ol><ins>Trends</ins></ol>
<ol>2. Growing reinsurance ceded abroad beyond the ASEAN region</ol>
<ol>3. Declining averages for Earned Premiums & Claims Incurred (with falling inflation rates)</ol>
<ol>4. Average ROC, Expense & Loss Ratios</ol>


<br>
<a href="https://medium.com/@DRicky.Ch29/python-web-scraping-data-analysis-motor-insurance-part-2-4cd7162ba644"><strong>Click To View</strong></a>
<br>



<br>





