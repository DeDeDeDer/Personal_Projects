# Personal_Projects
This GitHub holds all my personal project's that I have worked on as a past time. 
Project's are mainly focused on Data Science, Insurance Pricing & Reserving fields.
<br>A mapping of these are laid out below.
![ScreenShot](/Pictures/MapBackground_4.png)
<br>
<br>


> # **Insurance (Pricing) & Data Science**


<br>

# **What is Predictive Modelling?**

<br>
It is simply the framework to integrate past data & statistics to predict 
future outcomes or project liabilities. There are 4 main techniques;
Bayesian, Decision Trees, Support Vector Machines & Neural Networks.
My project's utilizes mainly Bayesian & Decision Tree techniques.
Hence, focused primarily on linear regression models.
<br>


.
<br>
## [At Its Simplest, Predictive Modelling](https://medium.com/@DRicky.Ch29/at-its-simplest-predictive-modelling-b3c0c0b0716d)
<br>

![ScreenShot](/Pictures/IntroModel_1.png)

An article publication aimed at explaining concepts to:
<br>1. Generalised structure to Predictive Modelling
<br>2. Alternative interpretations to various statistical model metrics
<br>
<br>The article follows the generalized framework of:
<br>
<ol><ins>Data preparation</ins></ol>
<ol>- Preliminary data analysis, executing 4-Tier's of data cleaning. (Correct, Complete, Create, Convert)</ol>

<ol><ins>Exploratory Data Analysis</ins></ol>
<ol>- Uni- Bi- & Multi- Analysis</ol>

<ol><ins>Model Preparation</ins></ol>
<ol>- Data stratified Train/Test splits, Hyper parameter tuning, parameter evaluation metrics.</ol>
<ol>- Feature Engineering (Quantity & Quality), Feature evaluation metrics</ol>

<ol><ins>Predictive Modelling (Classification Problem)</ins></ol>
<ol>- Ensembles (Hard & Soft Voting)</ol>

<br>
<a href="https://medium.com/@DRicky.Ch29/at-its-simplest-predictive-modelling-b3c0c0b0716d"><strong>Click To View</strong></a>
<br>



<br>

# **What is Web Scraping?**

<br>
In short, it is simply the automated process of extracting data from the web. 
Subsequently, cleaning any irregularities & conducting Exploratory Data Analysis
to spot Trends & Patterns.
<br>

.
<br>
## Python Web Scraping PDF & Data Cleaning (Part 1) 
[Article](https://medium.com/@DRicky.Ch29/web-scraping-pdf-tables-data-cleaning-part-1-cb6d8d47a6de)
or
[Code](https://medium.com/@DRicky.Ch29/web-scraping-pdf-tables-data-cleaning-part-1-cb6d8d47a6de)
<br>

![ScreenShot](/Pictures/WebScrapPart1.png)

A Python Kernel written to automate repetitive clicking of 1,228c URLs &
converting 1,000c PDF Tables into CSV to compile data.

<br>Contents:
<ol>1. Collate online source code URLs & sub-page URLs</ol>
<ol>2. Download online data via URLs</ol>
<ol>3. Convert & Neaten PDF Table into CSV</ol>
<ol>4. Compile all CSV Tables</ol>

<br>
<a href="https://medium.com/@DRicky.Ch29/web-scraping-pdf-tables-data-cleaning-part-1-cb6d8d47a6de"><strong>Click To View</strong></a>
<br>



.
<br>
## [Python Web Scraping Data Analysis Motor Insurance (Part 2)](https://medium.com/@DRicky.Ch29/python-web-scraping-data-analysis-motor-insurance-part-2-4cd7162ba644)
<br>

![ScreenShot](/Pictures/WebScrapPart2.png)

After extracting Annual Insurance Data Returns in the Part 1 series, we proceed to
analyze the data.

<br>Contents:
<ol><ins>Patterns</ins></ol>
<ol>1. Benchmark Range of ROC on Expense & Loss Ratios</ol>

<ol><ins>Trends</ins></ol>
<ol>2. Growing reinsurance ceded abroad beyond the ASEAN region</ol>
<ol>3. Declining averages for Earned Premiums & Claims Incurred (with falling inflation rates)</ol>
<ol>4. Average ROC, Expense & Loss Ratios</ol>


<br>
<a href="https://medium.com/@DRicky.Ch29/python-web-scraping-data-analysis-motor-insurance-part-2-4cd7162ba644"><strong>Click To View</strong></a>
<br>



<br>

# **What is Exploratory Data Analysis?**

<br>
It is simply the analyzing of data sets to summarize characteristics & patterns. 
These include Uni- Bi- & Multi- Variate Analysis. Often discovering underlying
relationships that conventional models overlook.
<br>

.
<br>
## [EDA & Feature Engineering Focused](https://www.kaggle.com/derrickchua29/feature-engineering-eda-focused/notebook)
<br>

![ScreenShot](/Pictures/EDA_article_1.png)


<br><ins>EDA Summary</ins>

<br>1. Those who have had past experience of financial distress (target variable):
<br>>Made lesser loans or exceed deadlines
<br>>Tend to have lesser dependents & debt ratio & net worth
<br>>As expected are of lower-tier income, But lower debt ratio
<br>

<br>2. Ignoring mortality and time value of money (i.e.Annuities)
<br>>Debt ratio & Net worth shows gaussian distribution against age
<br>

<br>3. Those who had acts of debt delinquency (Made loans or exceed deadlines)
<br>>Tend to be from the higher-tier income or Retired
<br>

<br>4. Others
<br>>The higher the income, the higher the debt ratio
<br>>The higher the income, the lower the dependents


<br>
<a href="https://www.kaggle.com/derrickchua29/feature-engineering-eda-focused/notebook"><strong>Click To View</strong></a>
<br>



# **What is General Linear Modelling?**

<br>
It is simply applying the fundamental straight line concept of a Y = mx + C. 
In other words, the idea that variable relationships are 1-dimensional (positive
or negative).
<br>


.<br>
## [Ensemble Models Comparison Techniques](https://www.kaggle.com/derrickchua29/ensemble-models-comparison-techniques)
<br>

![ScreenShot](/Pictures/GLM_article_1.png)


<br>A Python Kernel aimed at:
<ol>1. Get a better understanding of the simplified predictive modelling framework</ol>
<ol>2. Grasp the logic behind different coding methods & concise techniques used</ol>
<ol>3. Comparisons between different models</ol>
<br>
<ol><ins>Coding Techniques :</ins></ol>
<ol>A.List comprehensions</ol>
<ol>B.Samples to reduce computational cost</ol>
<ol>C.Concise 'def' functions that can be used repetitively</ol>
<ol>D.Pivoting using groupby</ol>
<ol>E.When & How to convert and reshape dictionaryâ€™s into lists or dataframes</ol>
<ol>F.Quickly split dataframe columns</ol>
<ol>H.Loop Sub-plots</ol>
<ol>I.Quick Lambda formulae functions</ol>
<ol>J.Quick looping print or DataFrame conversion of summative scores</ol>
<ol>K.Order plot components</ol>
<ol>L.Create & Plot Bulk Ensemble comparative results</ol>


<br>
<a href="https://www.kaggle.com/derrickchua29/ensemble-models-comparison-techniques"><strong>Click To View</strong></a>
<br>

<br>
<br>
<br>


> # **Insurance (Reserving)**


<br>

# **Claim Simulations**

<br>
In short, this projects contains a Python Kernel to automate the probabilistic  
claims simulation process for actuarial reserving calculations. 
<br>
Reserving Method Used: Inflation Adjusted Chain Ladder

.
<br>
## Claims Simulation 
[Article](https://medium.com/@DRicky.Ch29/inflation-adjusted-chain-ladder-iacl-with-only-python-pandas-module-512914d9a1d)
or
[Code](https://medium.com/@DRicky.Ch29/web-scraping-pdf-tables-data-cleaning-part-1-cb6d8d47a6de)
<br>

![ScreenShot](/Pictures/ClaimsSimu_article_1.png)

<br>Present: Simulation supports Claim Numbers (Poisson) & Amounts (Gaussian).
<br>Ongoing: 
<br>1. Claim Numbers (Negative Binomial) & Amounts (Lognormal).
<br>2. Support Bornhuetter-Ferguson Method (BF).

<br>Contents:
<ol>1. </ol>
<ol>2. </ol>
<ol>3. </ol>
<ol>4. </ol>

<br>
<a href="https://medium.com/@DRicky.Ch29/web-scraping-pdf-tables-data-cleaning-part-1-cb6d8d47a6de"><strong>Click To View</strong></a>
<br>


<br>





